{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.random.rand(73, 400)\n",
    "y_train = np.random.rand(73, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 2s 75ms/step - loss: 0.1912 - mean_squared_error: 0.1912 - val_loss: 0.1544 - val_mean_squared_error: 0.1544\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0924 - mean_squared_error: 0.0924 - val_loss: 0.1005 - val_mean_squared_error: 0.1005\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1106 - mean_squared_error: 0.1106 - val_loss: 0.1055 - val_mean_squared_error: 0.1055\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0990 - mean_squared_error: 0.0990 - val_loss: 0.0902 - val_mean_squared_error: 0.0902\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1028 - mean_squared_error: 0.1028 - val_loss: 0.1007 - val_mean_squared_error: 0.1007\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1081 - mean_squared_error: 0.1081 - val_loss: 0.0896 - val_mean_squared_error: 0.0896\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0849 - mean_squared_error: 0.0849 - val_loss: 0.0915 - val_mean_squared_error: 0.0915\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1016 - mean_squared_error: 0.1016 - val_loss: 0.1073 - val_mean_squared_error: 0.1073\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1140 - mean_squared_error: 0.1140 - val_loss: 0.0905 - val_mean_squared_error: 0.0905\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0790 - mean_squared_error: 0.0790 - val_loss: 0.0905 - val_mean_squared_error: 0.0905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1613735d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (4000,)\n",
    "\n",
    "# Define the model\n",
    "inputs = layers.Input(shape=input_shape)\n",
    "x = layers.Reshape((100, 40))(inputs)\n",
    "x = layers.MultiHeadAttention(num_heads=2, key_dim=32)(x, x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(8, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.mean_squared_error,\n",
    "    metrics=[keras.metrics.mean_squared_error],\n",
    ")\n",
    "\n",
    "# Generate some dummy data for training and testing\n",
    "x_train = np.random.rand(73, 4000)\n",
    "y_train = np.random.rand(73, )\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.random.rand(20, 4000)\n",
    "y_test = np.random.rand(20, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 149ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45983964],\n",
       "       [0.46452713],\n",
       "       [0.45363247],\n",
       "       [0.46818757],\n",
       "       [0.45089996],\n",
       "       [0.45645368],\n",
       "       [0.45923668],\n",
       "       [0.46747416],\n",
       "       [0.4592499 ],\n",
       "       [0.45967406],\n",
       "       [0.46044314],\n",
       "       [0.45692044],\n",
       "       [0.46306336],\n",
       "       [0.4472472 ],\n",
       "       [0.46270823],\n",
       "       [0.45486903],\n",
       "       [0.45669788],\n",
       "       [0.45245636],\n",
       "       [0.45297134],\n",
       "       [0.46158403]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "y_pred = tf.cast(model.predict(x_test), tf.int32)\n",
    "\n",
    "  # Calculate the mean squared error between the predictions and the ground truth labels.\n",
    "mse = mean_squared_error(y_pred, y_test)\n",
    "\n",
    "  # Calculate the root mean squared error between the predictions and the ground truth labels.\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "  # Calculate the mean absolute error between the predictions and the ground truth labels.\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "\n",
    "  # Calculate the R^2 score between the predictions and the ground truth labels.\n",
    "r2 = r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05395604358795354"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2322844023776748"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19293207410576058"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-71.71969858042739"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "# Define the original data with sampling rate of 100 Hz\n",
    "data_100hz = np.random.rand(1000)\n",
    "print(data_100hz.shape)\n",
    "# Define the desired sampling rate of 50 Hz\n",
    "new_fs = 50\n",
    "\n",
    "# Compute the decimation factor\n",
    "decimation_factor = int(round(100 / new_fs))\n",
    "\n",
    "# Downsample the data using decimation\n",
    "data_50hz = signal.decimate(data_100hz, decimation_factor, zero_phase=True)\n",
    "\n",
    "# Print the shape of the downsampled data\n",
    "print(data_50hz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 4.]\n"
     ]
    }
   ],
   "source": [
    "from scipy import signal\n",
    "\n",
    "# original data\n",
    "accel_data = [1, 2, 3, 4, 5]\n",
    "\n",
    "# define original and target sampling frequencies\n",
    "original_fs = 10\n",
    "target_fs = 5\n",
    "\n",
    "# calculate resampling factor\n",
    "resampling_factor = target_fs / original_fs\n",
    "\n",
    "# calculate new length of data\n",
    "new_length = int(len(accel_data) * resampling_factor)\n",
    "\n",
    "# resample data\n",
    "resampled_data = signal.resample(accel_data, new_length)\n",
    "\n",
    "print(resampled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "\n",
    "# Create sample data\n",
    "x = np.linspace(0, 10, num=1000)\n",
    "y = np.sin(x)\n",
    "\n",
    "# Set up resampling parameters\n",
    "orig_sampling_rate = 1000\n",
    "new_sampling_rate = 500\n",
    "new_num_samples = int(len(y) * (new_sampling_rate / orig_sampling_rate))\n",
    "\n",
    "# Perform spline interpolation\n",
    "tck = interpolate.splrep(x, y)\n",
    "new_x = np.linspace(x[0], x[-1], new_num_samples)\n",
    "new_y = interpolate.splev(new_x, tck)\n",
    "\n",
    "# Print the shape of the resampled data\n",
    "print(new_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_sampling_rate = 1000\n",
    "new_sampling_rate = 500\n",
    "new_num_samples = int(len(y) * (new_sampling_rate / orig_sampling_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "data = np.random.rand(1000)\n",
    "\n",
    "# Choose the downsampling factor.\n",
    "\n",
    "# Downsample the data.\n",
    "resampled_data = scipy.signal.resample(data, downsampling_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ノードを表すクラス\n",
    "class Node:\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "        self.neighbors = []\n",
    "        self.mpr = False\n",
    "\n",
    "    def add_neighbor(self, neighbor):\n",
    "        self.neighbors.append(neighbor)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Node \" + str(self.id)\n",
    "\n",
    "# MPR集合を計算する関数\n",
    "def calculate_mpr(node):\n",
    "    # すでにMPRに選ばれた隣接ノードを保持するリスト\n",
    "    mpr_neighbors = []\n",
    "\n",
    "    # 隣接ノードに対して\n",
    "    for neighbor in node.neighbors:\n",
    "        # 自分が隣接ノードのMPRに含まれている場合は、その隣接ノードは自分をMPRに含める\n",
    "        if node in neighbor.mpr_neighbors:\n",
    "            neighbor.mpr = True\n",
    "        else:\n",
    "            # 隣接ノードが自分の全ての隣接ノードをカバーする場合、その隣接ノードをMPRに含める\n",
    "            uncovered_neighbors = [n for n in neighbor.neighbors if n != node and n not in mpr_neighbors]\n",
    "            if set(uncovered_neighbors) == set(neighbor.mpr_neighbors):\n",
    "                neighbor.mpr = True\n",
    "                mpr_neighbors.append(neighbor)\n",
    "\n",
    "    # 自分が選ばれている隣接ノードを保持するリスト\n",
    "    node.mpr_neighbors = [n for n in node.neighbors if n.mpr]\n",
    "\n",
    "    # 自分自身が選ばれている場合、その隣接ノードをMPRに含める\n",
    "    if node.mpr:\n",
    "        for neighbor in node.neighbors:\n",
    "            neighbor.mpr = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0: []\n",
      "Node 1: []\n",
      "Node 2: []\n",
      "Node 3: []\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def compute_mpr_sets(graph: Dict[int, List[int]]) -> Dict[int, List[int]]:\n",
    "    # ノードの数\n",
    "    n = len(graph)\n",
    "\n",
    "    # すべてのノードのMPR集合を保存する辞書\n",
    "    mpr_sets = defaultdict(list)\n",
    "\n",
    "    for u in range(n):\n",
    "        # uの1ホップ近傍のノード\n",
    "        one_hop_neighbors = set(graph[u])\n",
    "\n",
    "        # 1ホップ近傍のノードが存在しない場合、MPR集合は空集合\n",
    "        if not one_hop_neighbors:\n",
    "            continue\n",
    "\n",
    "        # 1ホップ近傍のノードに到達するために必要な最小のノード集合\n",
    "        min_neighbors = set()\n",
    "        for v in one_hop_neighbors:\n",
    "            for w in graph[v]:\n",
    "                if w != u:\n",
    "                    min_neighbors.add(w)\n",
    "\n",
    "        # MPR集合を計算する\n",
    "        for v in one_hop_neighbors:\n",
    "            if v in min_neighbors:\n",
    "                mpr_sets[u].append(v)\n",
    "\n",
    "    return mpr_sets\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # ネットワークの作成\n",
    "    graph = {\n",
    "        0: [1, 2],\n",
    "        1: [0, 3],\n",
    "        2: [0, 3],\n",
    "        3: [1, 2],\n",
    "    }\n",
    "\n",
    "    # 各ノードのMPR集合を計算する\n",
    "    mpr_sets = compute_mpr_sets(graph)\n",
    "    for u in range(len(graph)):\n",
    "        print(f\"Node {u}: {mpr_sets[u]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "919e6181955fbc636a96e4fdb04fb1b969c9681582829f05a2534c8d07862e2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

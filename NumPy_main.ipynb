{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.random.rand(73, 400)\n",
    "y_train = np.random.rand(73, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 2s 75ms/step - loss: 0.1912 - mean_squared_error: 0.1912 - val_loss: 0.1544 - val_mean_squared_error: 0.1544\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0924 - mean_squared_error: 0.0924 - val_loss: 0.1005 - val_mean_squared_error: 0.1005\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1106 - mean_squared_error: 0.1106 - val_loss: 0.1055 - val_mean_squared_error: 0.1055\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0990 - mean_squared_error: 0.0990 - val_loss: 0.0902 - val_mean_squared_error: 0.0902\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1028 - mean_squared_error: 0.1028 - val_loss: 0.1007 - val_mean_squared_error: 0.1007\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1081 - mean_squared_error: 0.1081 - val_loss: 0.0896 - val_mean_squared_error: 0.0896\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0849 - mean_squared_error: 0.0849 - val_loss: 0.0915 - val_mean_squared_error: 0.0915\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1016 - mean_squared_error: 0.1016 - val_loss: 0.1073 - val_mean_squared_error: 0.1073\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1140 - mean_squared_error: 0.1140 - val_loss: 0.0905 - val_mean_squared_error: 0.0905\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0790 - mean_squared_error: 0.0790 - val_loss: 0.0905 - val_mean_squared_error: 0.0905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1613735d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (4000,)\n",
    "\n",
    "# Define the model\n",
    "inputs = layers.Input(shape=input_shape)\n",
    "x = layers.Reshape((100, 40))(inputs)\n",
    "x = layers.MultiHeadAttention(num_heads=2, key_dim=32)(x, x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(8, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.mean_squared_error,\n",
    "    metrics=[keras.metrics.mean_squared_error],\n",
    ")\n",
    "\n",
    "# Generate some dummy data for training and testing\n",
    "x_train = np.random.rand(73, 4000)\n",
    "y_train = np.random.rand(73, )\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.random.rand(20, 4000)\n",
    "y_test = np.random.rand(20, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 149ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45983964],\n",
       "       [0.46452713],\n",
       "       [0.45363247],\n",
       "       [0.46818757],\n",
       "       [0.45089996],\n",
       "       [0.45645368],\n",
       "       [0.45923668],\n",
       "       [0.46747416],\n",
       "       [0.4592499 ],\n",
       "       [0.45967406],\n",
       "       [0.46044314],\n",
       "       [0.45692044],\n",
       "       [0.46306336],\n",
       "       [0.4472472 ],\n",
       "       [0.46270823],\n",
       "       [0.45486903],\n",
       "       [0.45669788],\n",
       "       [0.45245636],\n",
       "       [0.45297134],\n",
       "       [0.46158403]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "y_pred = tf.cast(model.predict(x_test), tf.int32)\n",
    "\n",
    "  # Calculate the mean squared error between the predictions and the ground truth labels.\n",
    "mse = mean_squared_error(y_pred, y_test)\n",
    "\n",
    "  # Calculate the root mean squared error between the predictions and the ground truth labels.\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "  # Calculate the mean absolute error between the predictions and the ground truth labels.\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "\n",
    "  # Calculate the R^2 score between the predictions and the ground truth labels.\n",
    "r2 = r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05395604358795354"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2322844023776748"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19293207410576058"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-71.71969858042739"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "# Define the original data with sampling rate of 100 Hz\n",
    "data_100hz = np.random.rand(1000)\n",
    "print(data_100hz.shape)\n",
    "# Define the desired sampling rate of 50 Hz\n",
    "new_fs = 50\n",
    "\n",
    "# Compute the decimation factor\n",
    "decimation_factor = int(round(100 / new_fs))\n",
    "\n",
    "# Downsample the data using decimation\n",
    "data_50hz = signal.decimate(data_100hz, decimation_factor, zero_phase=True)\n",
    "\n",
    "# Print the shape of the downsampled data\n",
    "print(data_50hz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 4.]\n"
     ]
    }
   ],
   "source": [
    "from scipy import signal\n",
    "\n",
    "# original data\n",
    "accel_data = [1, 2, 3, 4, 5]\n",
    "\n",
    "# define original and target sampling frequencies\n",
    "original_fs = 10\n",
    "target_fs = 5\n",
    "\n",
    "# calculate resampling factor\n",
    "resampling_factor = target_fs / original_fs\n",
    "\n",
    "# calculate new length of data\n",
    "new_length = int(len(accel_data) * resampling_factor)\n",
    "\n",
    "# resample data\n",
    "resampled_data = signal.resample(accel_data, new_length)\n",
    "\n",
    "print(resampled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "\n",
    "# Create sample data\n",
    "x = np.linspace(0, 10, num=1000)\n",
    "y = np.sin(x)\n",
    "\n",
    "# Set up resampling parameters\n",
    "orig_sampling_rate = 1000\n",
    "new_sampling_rate = 500\n",
    "new_num_samples = int(len(y) * (new_sampling_rate / orig_sampling_rate))\n",
    "\n",
    "# Perform spline interpolation\n",
    "tck = interpolate.splrep(x, y)\n",
    "new_x = np.linspace(x[0], x[-1], new_num_samples)\n",
    "new_y = interpolate.splev(new_x, tck)\n",
    "\n",
    "# Print the shape of the resampled data\n",
    "print(new_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_sampling_rate = 1000\n",
    "new_sampling_rate = 500\n",
    "new_num_samples = int(len(y) * (new_sampling_rate / orig_sampling_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "data = np.random.rand(1000)\n",
    "\n",
    "# Choose the downsampling factor.\n",
    "\n",
    "# Downsample the data.\n",
    "resampled_data = scipy.signal.resample(data, downsampling_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 19:34:58.682642: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def transformer_regression(input_dim, output_dim):\n",
    "  \"\"\"Transformer regression model.\n",
    "\n",
    "  Args:\n",
    "    input_dim: The dimensionality of the input data.\n",
    "    output_dim: The dimensionality of the output data.\n",
    "\n",
    "  Returns:\n",
    "    A Transformer regression model.\n",
    "  \"\"\"\n",
    "\n",
    "  # Create the input layer.\n",
    "  input_layer = layers.Input(shape=(input_dim,))\n",
    "\n",
    "  # Create the embedding layer.\n",
    "  embedding_layer = layers.Embedding(input_dim, 128)\n",
    "\n",
    "  # Create the transformer encoder.\n",
    "  encoder = layers.TransformerEncoder(\n",
    "      num_layers=6,\n",
    "      hidden_size=512,\n",
    "      attention_heads=8,\n",
    "      dropout=0.1)\n",
    "\n",
    "  # Create the decoder.\n",
    "  decoder = layers.Dense(output_dim, activation='linear')\n",
    "\n",
    "  # Create the model.\n",
    "  model = tf.keras.Model(input_layer, decoder(encoder(embedding_layer(input_layer))))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras.layers' has no attribute 'TransformerEncoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m output_dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[39m# Create the model.\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m model \u001b[39m=\u001b[39m transformer_regression(input_dim, output_dim)\n\u001b[1;32m     11\u001b[0m \u001b[39m# Compile the model.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m, in \u001b[0;36mtransformer_regression\u001b[0;34m(input_dim, output_dim)\u001b[0m\n\u001b[1;32m     19\u001b[0m embedding_layer \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mEmbedding(input_dim, \u001b[39m128\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[39m# Create the transformer encoder.\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m encoder \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39;49mTransformerEncoder(\n\u001b[1;32m     23\u001b[0m     num_layers\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m,\n\u001b[1;32m     24\u001b[0m     hidden_size\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m,\n\u001b[1;32m     25\u001b[0m     attention_heads\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m,\n\u001b[1;32m     26\u001b[0m     dropout\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[39m# Create the decoder.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m decoder \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mDense(output_dim, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.layers' has no attribute 'TransformerEncoder'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the input and output dimensions of the model.\n",
    "input_dim = 4000\n",
    "output_dim = 1\n",
    "\n",
    "# Create the model.\n",
    "model = transformer_regression(input_dim, output_dim)\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model.\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "919e6181955fbc636a96e4fdb04fb1b969c9681582829f05a2534c8d07862e2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ライブラリをインポート\n",
    "import os #OSに依存する様々な機能を利用するためのモジュール(ファイルやディレクトリ操作など)\n",
    "import re #正規表現を利用するためのモジュール\n",
    "import csv  #csvファイルを扱うためのモジュール\n",
    "import math #数学的計算のためのモジュール\n",
    "import matplotlib.pyplot as plt #グラフ描画のためのモジュール\n",
    "import numpy as np  #多次元配列計算のためのモジュール\n",
    "import pandas as pd #データフレームを扱うためのモジュール\n",
    "from scipy.stats import skew, kurtosis  #歪度と尖度を調べるためのモジュール\n",
    "from sklearn.model_selection import train_test_split  #データをトレーニング用とテスト用に分けるためのモジュール\n",
    "from sklearn import preprocessing #データを正規化するためのモジュール\n",
    "from sklearn.preprocessing import StandardScaler  #データを標準化するためのモジュール\n",
    "from sklearn.preprocessing import LabelEncoder  #カテゴリ変数を数値化するためのモジュール\n",
    "from sklearn.linear_model import LinearRegression #線型回帰\n",
    "from sklearn.svm import SVC #サポートベクターマシン\n",
    "from sklearn.ensemble import RandomForestClassifier #ランダムフォレスト\n",
    "from sklearn.neighbors import KNeighborsClassifier  #k-近傍法\n",
    "from sklearn.metrics import accuracy_score  #機械学習モデルの性能評価のためのモジュール\n",
    "import xgboost as xgb #XGBoost\n",
    "import lightgbm as lgb  #LightGBM\n",
    "import tensorflow as tf #TensorFlow(Googleが開発したオープンソースの機械学習フレームワーク)\n",
    "from tensorflow import keras  #TensorFlow用のニューラルネットワークライブラリAPI\n",
    "from tensorflow.keras import layers #ニューラルネットワークのレイヤーを定義するためのモジュール\n",
    "import torch  #PyTorch\n",
    "import torch.nn as nn #ニューラルネットワークのためのモジュール\n",
    "import torch.optim as optim #パラメータの最適化を行うためのモジュール\n",
    "from torch.utils.data import DataLoader, Dataset  #データをバッチ単位でロードするためのユーティリティクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定数を定義\n",
    "BINS = 4000  #ヒストグラムのビンの数\n",
    "EPSILON = .00001  #スムージングパラメータ\n",
    "UPPER_LIMIT = 1.1 #静止区間の上限\n",
    "LOWER_LIMIT = 0.9 #静止区間の加減\n",
    "STATIONARY_INTERVALS = 5  #静止区間除去のサンプルの間隔(静止区間が何サンプル連続したら除去するか)\n",
    "TRAIN_SIZE = 0.8  #機械学習のトレーニングデータの割合\n",
    "N_ESTIMATORS = 100  #決定木の数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ディレクトリ内のAMWS020のデータセットのファイル名と周波数を取得する関数\n",
    "def get_Hz_and_filename(path: str) -> list[int, str]:\n",
    "    filename = os.listdir(path) #引数のパスのディレクトリの中のファイル名一覧を取得\n",
    "    Hz_and_filename=[]  #ファイル名と周波数を格納するリストを宣言\n",
    "\n",
    "    for file in filename:\n",
    "        Hz = re.search(r'\\d+', file)    #正規表現を用いてファイル名の中で一番最初に出てくる数字(周波数)を取得\n",
    "        if Hz:  #数字の入っていないファイル名があるとエラーを吐くので、このif文でチェックする\n",
    "            Hz_and_filename.append([int(Hz.group(0)), file])    #ファイル名と周波数を格納\n",
    "\n",
    "    return Hz_and_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ファイル名と周波数を分けて出力する関数\n",
    "def divide_Hz_and_filename(Hz_and_filename: list[int, str]) -> tuple[list[int], list[str]]:\n",
    "    Hz = []\n",
    "    filename = []\n",
    "    for row in Hz_and_filename:\n",
    "      Hz.append(row[0])\n",
    "      filename.append(row[1])\n",
    "\n",
    "    return Hz, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加速度データのCSVファイルから3軸加速度を取得する関数\n",
    "def get_acceleration(filename: str) -> tuple[list[float], list[float], list[float]]:\n",
    "    AccX, AccY, AccZ = [], [], []\n",
    "    with open(filename) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            AccX.append(float(row[2]))\n",
    "            AccY.append(float(row[3]))\n",
    "            AccZ.append(float(row[4]))\n",
    "\n",
    "    return AccX, AccY, AccZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#静止区間を除去する関数\n",
    "def remove_stationary_intervals(AccX: list[float], AccY: list[float], AccZ: list[float]) -> list[float]:\n",
    "    #各軸の加速度の平均を求める\n",
    "    AvgAccX = sum(AccX) / len(AccX)\n",
    "    AvgAccY = sum(AccY) / len(AccY)\n",
    "    AvgAccZ = sum(AccZ) / len(AccZ)\n",
    "\n",
    "    AvgResultantAcc = math.sqrt(AvgAccX ** 2 + AvgAccY ** 2 + AvgAccZ ** 2) #重力加速度の推定値=合成加速度の平均を求める\n",
    "\n",
    "    ResultantAcc = [math.sqrt(x ** 2 + y ** 2 + z ** 2) for x, y, z in zip(AccX, AccY, AccZ)]   #各時刻の合成加速度を求める\n",
    "\n",
    "    #各時刻の合成加速度から静止区間(重力加速度の推定値に近い値が一定以上以上連続している区間)を除去する\n",
    "    i = 0 #ループ変数\n",
    "    counter = 0 #静止区間がSTATIONARY_INTERVALS分続いているかをカウントする変数\n",
    "    while i < len(ResultantAcc):\n",
    "        if AvgResultantAcc * LOWER_LIMIT < ResultantAcc[i] < AvgResultantAcc * UPPER_LIMIT:   #平均のLOWER_LIMIT倍~UPPER_LIMIT倍の範囲を調べる\n",
    "            counter += 1    #範囲内ならカウントを増やす\n",
    "            if counter == STATIONARY_INTERVALS: #カウントがSTATIONARY_INTERVALSに達したらその区間を削除\n",
    "                del ResultantAcc[i+1-STATIONARY_INTERVALS:i+1]    #スライスでは選択範囲の開始位置startと終了位置stopを[start:stop]のように書くとstart <= x < stopの範囲が選択される #start番目の値は含まれるがstop番目の値は含まれない\n",
    "                counter = 0 #カウンターをリセット\n",
    "                i -= STATIONARY_INTERVALS   #削除した分インデックスがズレるので補正する\n",
    "        else:\n",
    "            counter = 0 #カウンターをリセット\n",
    "        i += 1\n",
    "\n",
    "    return ResultantAcc  #静止区間を除去した後のリストを返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#連続する2サンプルの差分を取る関数\n",
    "def calculate_differences_of_acceleration(ResultantAcc: list[float]) -> list[float]:\n",
    "    DifferenceAcc = [math.fabs(ResultantAcc[i + 1] * 100000 - ResultantAcc[i] * 100000) for i in range(len(ResultantAcc) - 1)]  #100000倍して誤差を取る\n",
    "    return DifferenceAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KLダイバージェンス関数 #引数として与える2つの分布は非負の値の集合でなければならないことに注意\n",
    "def KL_divergence(a: list[float], b: list[float]) -> float:\n",
    "    min_value = min(min(a), min(b)) #a,bの最小値の小さい方\n",
    "    max_value = max(max(a), max(b)) #a,bの最大値の大きい方\n",
    "\n",
    "    #a,bのヒストグラムを作成し、同じ数のビンで区切る\n",
    "    a_hist, _ = np.histogram(a, bins=BINS, range=(min_value, max_value))\n",
    "    b_hist, _ = np.histogram(b, bins=BINS, range=(min_value, max_value))\n",
    "\n",
    "    #正規化する(確率分布に変換する、合計を1にする)ために全合計で割る\n",
    "    a_hist = (a_hist + EPSILON) / a_hist.sum()\n",
    "    b_hist = (b_hist + EPSILON) / b_hist.sum()\n",
    "\n",
    "    #KLダイバージェンスの値を返す\n",
    "    return np.sum([ai * np.log(ai / bi) for ai, bi in zip(a_hist, b_hist)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSダイバージェンス関数 #引数として与える2つの分布は非負の値の集合でなければならないことに注意\n",
    "def JS_divergence(a: list[float], b: list[float]) -> float:\n",
    "    min_value = min(min(a), min(b)) #a,bの最小値の小さい方\n",
    "    max_value = max(max(a), max(b)) #a,bの最大値の大きい方\n",
    "\n",
    "    #a,bのヒストグラムを作成し、同じ数のビンで区切る\n",
    "    a_hist, _ = np.histogram(a, bins=BINS, range=(min_value, max_value))\n",
    "    b_hist, _ = np.histogram(b, bins=BINS, range=(min_value, max_value))\n",
    "\n",
    "    #正規化する(確率分布に変換する、合計を1にする)ために全合計で割る\n",
    "    a_hist = (a_hist + EPSILON) / a_hist.sum()\n",
    "    b_hist = (b_hist + EPSILON) / b_hist.sum()\n",
    "\n",
    "    #2つの分布の平均値を求める\n",
    "    mean_hist = (a_hist + b_hist) / 2.0\n",
    "\n",
    "    #平均とそれぞれの分布のKLダイバージェンスを算出\n",
    "    kl_a = np.sum([ai * np.log(ai / bi) for ai, bi in zip(a_hist, mean_hist)])\n",
    "    kl_b = np.sum([ai * np.log(ai / bi) for ai, bi in zip(b_hist, mean_hist)])\n",
    "\n",
    "    #JSダイバージェンスの値を返す\n",
    "    return (kl_a + kl_b) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データフレームの各行の中で2番目に小さい値が格納されている場所を調べる関数(最小値は同じ確率分布同士の0.0)\n",
    "def get_index_and_columns_of_second_smallest(df: pd.DataFrame) -> list[str, str]:\n",
    "    index_and_columns_of_second_smallest = []  #データフレームの中で2番目に小さい値が格納されている場所のインデックス名とカラム名を格納する変数\n",
    "    for i in range(len(df)):\n",
    "        sorted_row = df.iloc[i].sort_values()   #.ilocでデータフレームの要素を行、列の番号の添字で指定する    #各行の要素を昇順に並び替える\n",
    "        second_smallest_columns = sorted_row.index[1] #各行の2番目に小さい値が格納されているカラム[1]の名前を取得\n",
    "        #second_smallest_label = df.columns.get_loc(second_smallest_index)\n",
    "        index_and_columns_of_second_smallest.append((df.index[i], second_smallest_columns))    #インデックスとカラムのラベル名の組を二次元配列に追加\n",
    "    return index_and_columns_of_second_smallest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#推定精度を算出する関数\n",
    "def calculate_accuracy(index_and_columns_of_second_smallest: list[str, str]) -> tuple[float, list[int]]:\n",
    "    counter = 0\n",
    "    error_index_list = []\n",
    "    for i in range(len(index_and_columns_of_second_smallest)):\n",
    "        #インデックスとカラムのラベル名が同じならばカウンターを1増やす\n",
    "        if index_and_columns_of_second_smallest[i][0] == index_and_columns_of_second_smallest[i][1]:\n",
    "            counter += 1\n",
    "        else:\n",
    "            error_index_list.append(i)\n",
    "            print(f\"間違ってるやつは{i}番目の{index_and_columns_of_second_smallest[i][0]}と{index_and_columns_of_second_smallest[i][1]}です\")\n",
    "\n",
    "    return (counter / len(index_and_columns_of_second_smallest)) * 100, error_index_list  #精度を100分率で返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#入力された加速度の差分のリストからヒストグラムを作る関数（ビンの範囲が全加速度の差分データの最小値〜最大値）\n",
    "def create_histogram(DifferenceAcc_list: list[float]) -> np.histogram:\n",
    "    min_value = min(map(lambda x:max(x), DifferenceAcc_list))   #入力されたリストの中で最も小さい数\n",
    "    max_value = max(map(lambda x:max(x), DifferenceAcc_list))   #入力されたリストの中で最も大きい数\n",
    "\n",
    "    DifferenceAcc_hist = np.zeros((len(DifferenceAcc_list), BINS), dtype=float)\n",
    "\n",
    "    for i in range(len(DifferenceAcc_list)):\n",
    "        DifferenceAcc_hist[i], _ = np.histogram(DifferenceAcc_list[i], bins=BINS, range=(min_value, max_value)) #ヒストグラムを作成し、同じ数のビンで区切る\n",
    "    return DifferenceAcc_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#入力された加速度の差分のリストからヒストグラムを作る関数（ビンの範囲が各加速度の差分データの最小値〜最大値）\n",
    "def create_histogram2(DifferenceAcc_list: list[float]) -> np.histogram:\n",
    "    DifferenceAcc_hist = np.zeros((len(DifferenceAcc_list), BINS), dtype=float)\n",
    "    for i in range(len(DifferenceAcc_list)):\n",
    "        min_value = min(DifferenceAcc_list[i])\n",
    "        max_value = max(DifferenceAcc_list[i])\n",
    "        #DifferenceAcc_hist[i], _ = np.histogram(DifferenceAcc_list[i], bins=BINS, range=(min_value, max_value)) #ヒストグラムを作成し、同じ数のビンで区切る\n",
    "        DifferenceAcc_hist[i], _ = np.histogram(DifferenceAcc_list[i], bins=BINS) #ヒストグラムを作成し、同じ数のビンで区切る\n",
    "    return DifferenceAcc_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KLダイバージェンスとJSダイバージェンス算出の一連の流れを自動化した関数\n",
    "def KL_and_JS(path: str):\n",
    "    Hz_and_filename = get_Hz_and_filename(path)\n",
    "    Hz_and_filename.sort(reverse=True)  #周波数の大きい順にソート\n",
    "    Hz, filename = divide_Hz_and_filename(Hz_and_filename)\n",
    "    Hz = [str(hz) + \"Hz\" for hz in Hz]  #周波数の値+\"Hz\"のリストを作りデータフレームのラベルに用いる\n",
    "\n",
    "    #使う変数を宣言\n",
    "    AccX, AccY, AccZ = [], [], []\n",
    "    ResultantAcc = []\n",
    "    DifferenceAcc_list = []\n",
    "    resultKLD = [[0.0 for j in range(len(filename))] for i in range(len(filename))]  # resultKLDの要素を0.0で初期化\n",
    "    resultJSD = [[0.0 for j in range(len(filename))] for i in range(len(filename))]  # resultKLDの要素を0.0で初期化\n",
    "    error_index_list = []\n",
    "\n",
    "    #各データセットからデータを読み込み静止区間を除去したものを二次元配列に格納\n",
    "    for i in filename:\n",
    "        AccX, AccY, AccZ = get_acceleration(path+i)\n",
    "        ResultantAcc = remove_stationary_intervals(AccX, AccY, AccZ)\n",
    "        DifferenceAcc_list.append(calculate_differences_of_acceleration(ResultantAcc))\n",
    "\n",
    "    #KLダイバージェンスの値を格納\n",
    "    for i in range(len(filename)):\n",
    "        for j in range(len(filename)):\n",
    "            resultKLD[i][j] = KL_divergence(DifferenceAcc_list[i], DifferenceAcc_list[j])\n",
    "\n",
    "    #JSダイバージェンスの値を格納\n",
    "    for i in range(len(filename)):\n",
    "        for j in range(len(filename)):\n",
    "            resultJSD[i][j] = JS_divergence(DifferenceAcc_list[i], DifferenceAcc_list[j])\n",
    "\n",
    "    #結果を出力\n",
    "    df_KLD = pd.DataFrame(resultKLD, index=Hz, columns=Hz)\n",
    "    display(df_KLD)\n",
    "    accuracyKLD, error_index_list = calculate_accuracy(get_index_and_columns_of_second_smallest(df_KLD))\n",
    "    for i in range(len(error_index_list)):\n",
    "        print(filename[error_index_list[i]])\n",
    "    print(f\"KLダイバージェンスによる推定精度は{accuracyKLD}%です\")\n",
    "\n",
    "    df_JSD = pd.DataFrame(resultJSD, index=Hz, columns=Hz)\n",
    "    display(df_JSD)\n",
    "    accuracyJSD, error_index_list = calculate_accuracy(get_index_and_columns_of_second_smallest(df_JSD))\n",
    "    for i in range(len(error_index_list)):\n",
    "        print(filename[error_index_list[i]])\n",
    "    print(f\"JSダイバージェンスによる推定精度は{accuracyJSD}%です\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ランダムフォレストによる機械学習モデル構築と性能評価までを自動化した関数\n",
    "def random_forest(path: str):\n",
    "    Hz_and_filename = get_Hz_and_filename(path)\n",
    "    Hz_and_filename.sort(reverse=True)  #周波数の大きい順にソート\n",
    "    Hz, filename = divide_Hz_and_filename(Hz_and_filename)\n",
    "\n",
    "    #使う変数を宣言\n",
    "    AccX, AccY, AccZ = [], [], []\n",
    "    ResultantAcc = []\n",
    "    DifferenceAcc_list = []\n",
    "\n",
    "    #各データセットからデータを読み込み静止区間を除去したものを二次元配列に格納\n",
    "    for i in filename:\n",
    "        AccX, AccY, AccZ = get_acceleration(path+i)\n",
    "        ResultantAcc = remove_stationary_intervals(AccX, AccY, AccZ)\n",
    "        DifferenceAcc_list.append(calculate_differences_of_acceleration(ResultantAcc))\n",
    "\n",
    "    DifferenceAcc_hist = create_histogram2(DifferenceAcc_list)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(DifferenceAcc_hist, Hz, train_size = TRAIN_SIZE, shuffle = True)\n",
    "\n",
    "    # 学習する\n",
    "    clf = RandomForestClassifier(n_estimators=N_ESTIMATORS, random_state=1234)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(\"正解率 = \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-近傍法による機械学習モデル構築と性能評価までを自動化した関数\n",
    "def k_neighbors(path: str):\n",
    "    Hz_and_filename = get_Hz_and_filename(path)\n",
    "    Hz_and_filename.sort(reverse=True)  #周波数の大きい順にソート\n",
    "    Hz, filename = divide_Hz_and_filename(Hz_and_filename)\n",
    "\n",
    "    #使う変数を宣言\n",
    "    AccX, AccY, AccZ = [], [], []\n",
    "    ResultantAcc = []\n",
    "    DifferenceAcc_list = []\n",
    "\n",
    "    #各データセットからデータを読み込み静止区間を除去したものを二次元配列に格納\n",
    "    for i in filename:\n",
    "        AccX, AccY, AccZ = get_acceleration(path+i)\n",
    "        ResultantAcc = remove_stationary_intervals(AccX, AccY, AccZ)\n",
    "        DifferenceAcc_list.append(calculate_differences_of_acceleration(ResultantAcc))\n",
    "\n",
    "    DifferenceAcc_hist = create_histogram2(DifferenceAcc_list)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(DifferenceAcc_hist)\n",
    "    newdata = scaler.transform(DifferenceAcc_hist)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(newdata, Hz, train_size = TRAIN_SIZE, shuffle = True)\n",
    "\n",
    "    # 学習する\n",
    "    clf = KNeighborsClassifier()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(\"正解率 = \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoostによる機械学習モデル構築と性能評価までを自動化した関数\n",
    "def xgboost(path: str):\n",
    "    Hz_and_filename = get_Hz_and_filename(path)\n",
    "    Hz_and_filename.sort(reverse=True)  #周波数の大きい順にソート\n",
    "    Hz, filename = divide_Hz_and_filename(Hz_and_filename)\n",
    "\n",
    "    #使う変数を宣言\n",
    "    AccX, AccY, AccZ = [], [], []\n",
    "    ResultantAcc = []\n",
    "    DifferenceAcc_list = []\n",
    "\n",
    "    #各データセットからデータを読み込み静止区間を除去したものを二次元配列に格納\n",
    "    for i in filename:\n",
    "        AccX, AccY, AccZ = get_acceleration(path+i)\n",
    "        ResultantAcc = remove_stationary_intervals(AccX, AccY, AccZ)\n",
    "        DifferenceAcc_list.append(calculate_differences_of_acceleration(ResultantAcc))\n",
    "\n",
    "    DifferenceAcc_hist = create_histogram2(DifferenceAcc_list)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    Hz = le.fit_transform(Hz)\n",
    "    # 学習する\n",
    "    x_train, x_test, y_train, y_test = train_test_split(DifferenceAcc_hist, Hz, train_size = TRAIN_SIZE, shuffle = True)\n",
    "    clf = xgb.XGBClassifier(objective='multi:softmax')\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(\"正解率 = \", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"my_walk_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#個々実験用\n",
    "Hz_and_filename = get_Hz_and_filename(path)\n",
    "Hz_and_filename.sort(reverse=True)  #周波数の大きい順にソート\n",
    "Hz, filename = divide_Hz_and_filename(Hz_and_filename)\n",
    "\n",
    "#使う変数を宣言\n",
    "AccX, AccY, AccZ = [], [], []\n",
    "ResultantAcc = []\n",
    "DifferenceAcc_list = []\n",
    "\n",
    "#各データセットからデータを読み込み静止区間を除去したものを二次元配列に格納\n",
    "for i in filename:\n",
    "    AccX, AccY, AccZ = get_acceleration(path+i)\n",
    "    ResultantAcc = remove_stationary_intervals(AccX, AccY, AccZ)\n",
    "    DifferenceAcc_list.append(calculate_differences_of_acceleration(ResultantAcc))\n",
    "\n",
    "DifferenceAcc_hist = create_histogram2(DifferenceAcc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#尖度\n",
    "DifferenceAcc_kurtosis = np.zeros(len(DifferenceAcc_hist))\n",
    "for i in range(len(DifferenceAcc_hist)):\n",
    "    DifferenceAcc_kurtosis[i] = kurtosis(DifferenceAcc_hist[i])\n",
    "\n",
    "#歪度\n",
    "DifferenceAcc_skewness = np.zeros(len(DifferenceAcc_hist))\n",
    "for i in range(len(DifferenceAcc_hist)):\n",
    "    DifferenceAcc_skewness[i] = skew(DifferenceAcc_hist[i])\n",
    "\n",
    "#分散\n",
    "histogram_var = np.zeros(len(DifferenceAcc_list))\n",
    "for i in range(len(DifferenceAcc_hist)):\n",
    "    histogram_var[i] = np.var(DifferenceAcc_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_newに尖度＋歪度+分散を連結したもの\n",
    "X_new = np.concatenate((DifferenceAcc_kurtosis.reshape(-1, 1), DifferenceAcc_skewness.reshape(-1, 1), histogram_var.reshape(-1, 1)), axis=1)\n",
    "#XはDifferenceAcc_hist+X_new\n",
    "X = np.concatenate((DifferenceAcc_hist, X_new), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "Hz = le.fit_transform(Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models. Sequential([\n",
    "    tf.keras.layers.Dense(4, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(3, activation=tf.nn.softmax),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(\"正解率 = \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformerブロックの実装\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation='relu'),\n",
    "            Dense(d_model)\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        attn_output = self.att(x, x)\n",
    "        x = x + attn_output\n",
    "        x = self.layernorm1(x)\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = x + ffn_output\n",
    "        x = self.layernorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "# Transformerモデルの構築\n",
    "class TransformerRegressionModel(tf.keras.Model):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, num_blocks, input_shape):\n",
    "        super(TransformerRegressionModel, self).__init__()\n",
    "        self.input_shape_ = input_shape\n",
    "        self.embedding = Dense(d_model, input_shape=input_shape)\n",
    "        self.transformer_blocks = [TransformerBlock(d_model, num_heads, ff_dim) for _ in range(num_blocks)]\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc = Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        for transformer_block in self.transformer_blocks:\n",
    "            x = transformer_block(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのインスタンス化\n",
    "d_model = 64  # トランスフォーマーブロックの隠れ層の次元数\n",
    "num_heads = 4  # Multi-Head Attentionのヘッドの数\n",
    "ff_dim = 128  # Position-wise Feed-Forward Networkの隠れ層の次元数\n",
    "num_blocks = 4  # トランスフォーマーブロックの数\n",
    "input_shape = (100, 3)  # 入力データの形状 (バッチサイズ, シーケンスの長さ, 特徴量の次元数)\n",
    "\n",
    "model = TransformerRegressionModel(d_model, num_heads, ff_dim, num_blocks, input_shape)\n",
    "\n",
    "# モデルのコンパイル\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "loss = MeanSquaredError()\n",
    "model.compile(optimizer=optimizer, loss=loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(scaler.fit_transform(DifferenceAcc_hist), scaler.fit_transform(np.array(Hz)), train_size = TRAIN_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの学習\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "print(\"正解率 = \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MultiHeadAttention.call() missing 1 required positional argument: 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m EPOCHS \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[39m# モデルの構築\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m model \u001b[39m=\u001b[39m transformer_model(input_shape\u001b[39m=\u001b[39;49m(\u001b[39m100\u001b[39;49m, \u001b[39m10\u001b[39;49m), d_model\u001b[39m=\u001b[39;49mD_MODEL, num_heads\u001b[39m=\u001b[39;49mNUM_HEADS, num_layers\u001b[39m=\u001b[39;49mNUM_LAYERS, dropout_rate\u001b[39m=\u001b[39;49mDROPOUT_RATE)\n\u001b[1;32m     51\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mAdam(LEARNING_RATE), loss\u001b[39m=\u001b[39mMeanSquaredError())\n\u001b[1;32m     53\u001b[0m \u001b[39m# データの読み込みと学習\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[40], line 25\u001b[0m, in \u001b[0;36mtransformer_model\u001b[0;34m(input_shape, d_model, num_heads, num_layers, dropout_rate)\u001b[0m\n\u001b[1;32m     23\u001b[0m encoder \u001b[39m=\u001b[39m embedding\n\u001b[1;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_layers):\n\u001b[0;32m---> 25\u001b[0m     encoder \u001b[39m=\u001b[39m MultiHeadAttention(num_heads\u001b[39m=\u001b[39;49mnum_heads, key_dim\u001b[39m=\u001b[39;49md_model)([encoder, encoder])\n\u001b[1;32m     26\u001b[0m     encoder \u001b[39m=\u001b[39m Dropout(dropout_rate)(encoder)\n\u001b[1;32m     27\u001b[0m     encoder \u001b[39m=\u001b[39m LayerNormalization(epsilon\u001b[39m=\u001b[39m\u001b[39m1e-6\u001b[39m)(encoder)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: MultiHeadAttention.call() missing 1 required positional argument: 'value'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Embedding, LayerNormalization, MultiHeadAttention, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "def transformer_model(input_shape, d_model=64, num_heads=4, num_layers=4, dropout_rate=0.2):\n",
    "    \"\"\"\n",
    "    Transformer回帰モデルの定義\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Embedding層\n",
    "    embedding = Embedding(input_dim=input_shape[0], output_dim=d_model)(inputs)\n",
    "    embedding = Dropout(dropout_rate)(embedding)\n",
    "\n",
    "    # Positional Encoding\n",
    "    position = tf.range(start=0, limit=input_shape[1], delta=1)\n",
    "    position_embedding = Embedding(input_shape[1], d_model)(position)\n",
    "    embedding = tf.math.add(embedding, position_embedding)\n",
    "\n",
    "    # Encoder\n",
    "    encoder = embedding\n",
    "    for i in range(num_layers):\n",
    "        encoder = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)([encoder, encoder])\n",
    "        encoder = Dropout(dropout_rate)(encoder)\n",
    "        encoder = LayerNormalization(epsilon=1e-6)(encoder)\n",
    "        ffn = TimeDistributed(Dense(d_model, activation='relu'))(encoder)\n",
    "        ffn = TimeDistributed(Dense(d_model))(ffn)\n",
    "        encoder = Dropout(dropout_rate)(ffn)\n",
    "        encoder = LayerNormalization(epsilon=1e-6)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    decoder = Dense(d_model, activation='relu')(encoder)\n",
    "    decoder = Dense(1)(decoder)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=decoder)\n",
    "    return model\n",
    "\n",
    "# ハイパーパラメーターの設定\n",
    "D_MODEL = 64\n",
    "NUM_HEADS = 4\n",
    "NUM_LAYERS = 4\n",
    "DROPOUT_RATE = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# モデルの構築\n",
    "model = transformer_model(input_shape=(100, 10), d_model=D_MODEL, num_heads=NUM_HEADS, num_layers=NUM_LAYERS, dropout_rate=DROPOUT_RATE)\n",
    "model.compile(optimizer=Adam(LEARNING_RATE), loss=MeanSquaredError())\n",
    "\n",
    "# データの読み込みと学習\n",
    "x_train, x_test, y_train, y_test = train_test_split(DifferenceAcc_hist, Hz, train_size = TRAIN_SIZE, shuffle = True)\n",
    "x_train_normalized = normalize(x_train)  # データの正規化\n",
    "model.fit(x_train_normalized, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 2s 4ms/step - loss: 0.4177\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3098\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2237\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1604\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1179\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0944\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0810\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0778\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0783\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0791\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "[[[0.47213274]\n",
      "  [0.471031  ]\n",
      "  [0.4707787 ]\n",
      "  [0.47264546]\n",
      "  [0.47259188]\n",
      "  [0.47177172]\n",
      "  [0.47214592]\n",
      "  [0.47264034]\n",
      "  [0.47220987]\n",
      "  [0.47259307]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Prepare the data\n",
    "x_train = np.random.rand(100, 10, 3) # 100 sequences of 10 timesteps with 3 features\n",
    "y_train = np.random.rand(100, 1) # 100 target values\n",
    "\n",
    "# Define the model architecture\n",
    "inputs = keras.Input(shape=(10, 3))\n",
    "attn_output = layers.MultiHeadAttention(num_heads=2, key_dim=2)(inputs, inputs)\n",
    "attn_output = layers.LayerNormalization(epsilon=1e-6)(attn_output)\n",
    "ffn_output = layers.Dense(32, activation=\"relu\")(attn_output)\n",
    "ffn_output = layers.Dense(1)(ffn_output)\n",
    "outputs = layers.Activation(\"linear\")(ffn_output)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Make predictions\n",
    "x_test = np.random.rand(1, 10, 3) # 1 sequence of 10 timesteps with 3 features\n",
    "y_pred = model.predict(x_test)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 2s 2ms/step - loss: 0.4996\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4996\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4995\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4996\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4997\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4996\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4995\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4996\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4995\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4996\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4996\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4995\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4998\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4995\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4995\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4996\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4995\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4996\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4996\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4996\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4995\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4995\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4996\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4995\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4995\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4996\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4995\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4995\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4996\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4996\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4995\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4996\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4997\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4996\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4996\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4998\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4996\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4997\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4998\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4995\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4996\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4995\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4995\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Prepare the data\n",
    "x_train = np.linspace(0, 2*np.pi, 1000)\n",
    "y_train = np.sin(x_train)\n",
    "\n",
    "# Define the model architecture\n",
    "inputs = keras.Input(shape=(None, 1))\n",
    "attn_output = layers.MultiHeadAttention(num_heads=8, key_dim=1)(inputs, inputs)\n",
    "attn_output = layers.LayerNormalization(epsilon=1e-6)(attn_output)\n",
    "ffn_output = layers.Dense(32, activation=\"relu\")(attn_output)\n",
    "ffn_output = layers.Dense(1)(ffn_output)\n",
    "outputs = layers.Activation(\"linear\")(ffn_output)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "x_train = x_train.reshape((x_train.shape[0], 1, 1))\n",
    "y_train = y_train.reshape((y_train.shape[0], 1))\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# Make predictions\n",
    "x_test = np.linspace(0, 2*np.pi, 100)\n",
    "x_test = x_test.reshape((x_test.shape[0], 1, 1))\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_train.reshape((-1,)), y_train.reshape((-1,)), label='Training Data')\n",
    "plt.plot(x_test.reshape((-1,)), y_pred.reshape((-1,)), label='Predictions')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 10s 7ms/step - loss: 1.9732\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7060\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5933\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5686\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5446\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5267\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5640\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5093\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4865\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15430ce10>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "# Transformerブロックの実装\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation='relu'),\n",
    "            Dense(d_model)\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        attn_output = self.att(x, x)\n",
    "        x = x + attn_output\n",
    "        x = self.layernorm1(x)\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = x + ffn_output\n",
    "        x = self.layernorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "# Transformerモデルの構築\n",
    "class TransformerRegressionModel(tf.keras.Model):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, num_blocks, input_shape):\n",
    "        super(TransformerRegressionModel, self).__init__()\n",
    "        self.input_shape_ = input_shape\n",
    "        self.embedding = Dense(d_model, input_shape=input_shape)\n",
    "        self.transformer_blocks = [TransformerBlock(d_model, num_heads, ff_dim) for _ in range(num_blocks)]\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc = Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        for transformer_block in self.transformer_blocks:\n",
    "            x = transformer_block(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# モデルのインスタンス化\n",
    "d_model = 64  # トランスフォーマーブロックの隠れ層の次元数\n",
    "num_heads = 4  # Multi-Head Attentionのヘッドの数\n",
    "ff_dim = 128  # Position-wise Feed-Forward Networkの隠れ層の次元数\n",
    "num_blocks = 4  # トランスフォーマーブロックの数\n",
    "input_shape = (100, 3)  # 入力データの形状 (バッチサイズ, シーケンスの長さ, 特徴量の次元数)\n",
    "\n",
    "model = TransformerRegressionModel(d_model, num_heads, ff_dim, num_blocks, input_shape)\n",
    "\n",
    "# モデルのコンパイル\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "loss = MeanSquaredError()\n",
    "model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "# モデルの学習\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "919e6181955fbc636a96e4fdb04fb1b969c9681582829f05a2534c8d07862e2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

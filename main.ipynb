{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ライブラリをインポート\n",
    "import os #OSに依存する様々な機能を利用するためのモジュール(ファイルやディレクトリ操作など)\n",
    "import re #正規表現を利用するためのモジュール\n",
    "import csv  #csvファイルを扱うためのモジュール\n",
    "import math #数学的計算のためのモジュール\n",
    "import matplotlib.pyplot as plt #グラフ描画のためのモジュール\n",
    "import numpy as np  #多次元配列計算のためのモジュール\n",
    "import pandas as pd #データフレームを扱うためのモジュール\n",
    "from scipy.stats import skew, kurtosis  #歪度と尖度を調べるためのモジュール\n",
    "from sklearn.model_selection import train_test_split  #データをトレーニング用とテスト用に分けるためのモジュール\n",
    "from sklearn import preprocessing #データを正規化するためのモジュール\n",
    "from sklearn.preprocessing import StandardScaler  #データを標準化するためのモジュール\n",
    "from sklearn.linear_model import LinearRegression #線型回帰\n",
    "from sklearn.svm import SVC #サポートベクターマシン\n",
    "from sklearn.ensemble import RandomForestClassifier #ランダムフォレスト\n",
    "from sklearn.neighbors import KNeighborsClassifier  #k-近傍法\n",
    "from sklearn.metrics import accuracy_score  #機械学習モデルの性能評価のためのモジュール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定数を定義\n",
    "BINS = 4000  #ヒストグラムのビンの数\n",
    "EPSILON = .00001  #スムージングパラメータ\n",
    "UPPER_LIMIT = 1.1 #静止区間の上限\n",
    "LOWER_LIMIT = 0.9 #静止区間の加減\n",
    "STATIONARY_INTERVALS = 5  #静止区間除去のサンプルの間隔(静止区間が何サンプル連続したら除去するか)\n",
    "TRAIN_SIZE = 0.8  #ランダムフォレストのトレーニングデータの割合\n",
    "N_ESTIMATORS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ディレクトリ内のデータセットのファイル名と周波数を取得する関数\n",
    "def get_Hz_and_filename(path: str) -> list[int, str]:\n",
    "    filename = os.listdir(path) #引数のパスのディレクトリの中のファイル名一覧を取得\n",
    "    Hz_and_filename=[]  #ファイル名と周波数を格納するリストを宣言\n",
    "\n",
    "    for file in filename:\n",
    "        Hz = re.search(r'\\d+', file)    #正規表現を用いてファイル名の中で一番最初に出てくる数字(周波数)を取得\n",
    "        if Hz:  #数字の入っていないファイル名があるとエラーを吐くので、このif文でチェックする\n",
    "            Hz_and_filename.append([int(Hz.group(0)), file])    #ファイル名と周波数を格納\n",
    "\n",
    "    return Hz_and_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ファイル名と周波数を分けて出力する関数\n",
    "def divide_Hz_and_filename(Hz_and_filename: list[int, str]) -> tuple[list[int], list[str]]:\n",
    "    Hz = []\n",
    "    filename = []\n",
    "    for row in Hz_and_filename:\n",
    "      Hz.append(row[0])\n",
    "      filename.append(row[1])\n",
    "\n",
    "    return Hz, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加速度データのCSVファイルから3軸加速度を取得する関数\n",
    "def get_acceleration(filename: str) -> tuple[list[float], list[float], list[float]]:\n",
    "    AccX, AccY, AccZ = [], [], []\n",
    "    with open(filename) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            AccX.append(float(row[2]))\n",
    "            AccY.append(float(row[3]))\n",
    "            AccZ.append(float(row[4]))\n",
    "\n",
    "    return AccX, AccY, AccZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#静止区間を除去する関数\n",
    "def remove_stationary_intervals(AccX: list[float], AccY: list[float], AccZ: list[float]) -> list[float]:\n",
    "    #各軸の加速度の平均を求める\n",
    "    AvgAccX = sum(AccX) / len(AccX)\n",
    "    AvgAccY = sum(AccY) / len(AccY)\n",
    "    AvgAccZ = sum(AccZ) / len(AccZ)\n",
    "\n",
    "    AvgResultantAcc = math.sqrt(AvgAccX ** 2 + AvgAccY ** 2 + AvgAccZ ** 2) #重力加速度の推定値=合成加速度の平均を求める\n",
    "\n",
    "    ResultantAcc = [math.sqrt(x ** 2 + y ** 2 + z ** 2) for x, y, z in zip(AccX, AccY, AccZ)]   #各時刻の合成加速度を求める\n",
    "\n",
    "    #各時刻の合成加速度から静止区間(重力加速度の推定値に近い値が一定以上以上連続している区間)を除去する\n",
    "    i = 0 #ループ変数\n",
    "    counter = 0 #静止区間がSTATIONARY_INTERVALS分続いているかをカウントする変数\n",
    "    while i < len(ResultantAcc):\n",
    "        if AvgResultantAcc * LOWER_LIMIT < ResultantAcc[i] < AvgResultantAcc * UPPER_LIMIT:   #平均のLOWER_LIMIT倍~UPPER_LIMIT倍の範囲を調べる\n",
    "            counter += 1    #範囲内ならカウントを増やす\n",
    "            if counter == STATIONARY_INTERVALS: #カウントがSTATIONARY_INTERVALSに達したらその区間を削除\n",
    "                del ResultantAcc[i+1-STATIONARY_INTERVALS:i+1]    #スライスでは選択範囲の開始位置startと終了位置stopを[start:stop]のように書くとstart <= x < stopの範囲が選択される #start番目の値は含まれるがstop番目の値は含まれない\n",
    "                counter = 0 #カウンターをリセット\n",
    "                i -= STATIONARY_INTERVALS   #削除した分インデックスがズレるので補正する\n",
    "        else:\n",
    "            counter = 0 #カウンターをリセット\n",
    "        i += 1\n",
    "\n",
    "    return ResultantAcc  #静止区間を除去した後のリストを返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#連続する2サンプルの差分を取る関数\n",
    "def calculate_differences_of_acceleration(ResultantAcc: list[float]) -> list[float]:\n",
    "    DifferenceAcc = [math.fabs(ResultantAcc[i + 1] * 100000 - ResultantAcc[i] * 100000) for i in range(len(ResultantAcc) - 1)]  #100000倍して誤差を取る\n",
    "    return DifferenceAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KLダイバージェンス関数 #引数として与える2つの分布は非負の値の集合でなければならないことに注意\n",
    "def KL_divergence(a: list[float], b: list[float]) -> float:\n",
    "    min_value = min(min(a), min(b)) #a,bの最小値の小さい方\n",
    "    max_value = max(max(a), max(b)) #a,bの最大値の大きい方\n",
    "\n",
    "    #a,bのヒストグラムを作成し、同じ数のビンで区切る\n",
    "    a_hist, _ = np.histogram(a, bins=BINS, range=(min_value, max_value))\n",
    "    b_hist, _ = np.histogram(b, bins=BINS, range=(min_value, max_value))\n",
    "\n",
    "    #正規化する(確率分布に変換する、合計を1にする)ために全合計で割る\n",
    "    a_hist = (a_hist + EPSILON) / a_hist.sum()\n",
    "    b_hist = (b_hist + EPSILON) / b_hist.sum()\n",
    "\n",
    "    #KLダイバージェンスの値を返す\n",
    "    return np.sum([ai * np.log(ai / bi) for ai, bi in zip(a_hist, b_hist)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSダイバージェンス関数 #引数として与える2つの分布は非負の値の集合でなければならないことに注意\n",
    "def JS_divergence(a: list[float], b: list[float]) -> float:\n",
    "    min_value = min(min(a), min(b)) #a,bの最小値の小さい方\n",
    "    max_value = max(max(a), max(b)) #a,bの最大値の大きい方\n",
    "\n",
    "    #a,bのヒストグラムを作成し、同じ数のビンで区切る\n",
    "    a_hist, _ = np.histogram(a, bins=BINS, range=(min_value, max_value))\n",
    "    b_hist, _ = np.histogram(b, bins=BINS, range=(min_value, max_value))\n",
    "\n",
    "    #正規化する(確率分布に変換する、合計を1にする)ために全合計で割る\n",
    "    a_hist = (a_hist + EPSILON) / a_hist.sum()\n",
    "    b_hist = (b_hist + EPSILON) / b_hist.sum()\n",
    "\n",
    "    #2つの分布の平均値を求める\n",
    "    mean_hist = (a_hist + b_hist) / 2.0\n",
    "\n",
    "    #平均とそれぞれの分布のKLダイバージェンスを算出\n",
    "    kl_a = np.sum([ai * np.log(ai / bi) for ai, bi in zip(a_hist, mean_hist)])\n",
    "    kl_b = np.sum([ai * np.log(ai / bi) for ai, bi in zip(b_hist, mean_hist)])\n",
    "\n",
    "    #JSダイバージェンスの値を返す\n",
    "    return (kl_a + kl_b) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データフレームの各行の中で2番目に小さい値が格納されている場所を調べる関数(最小値は同じ確率分布同士の0.0)\n",
    "def get_index_and_columns_of_second_smallest(df: pd.DataFrame) -> list[str, str]:\n",
    "    index_and_columns_of_second_smallest = []  #データフレームの中で2番目に小さい値が格納されている場所のインデックス名とカラム名を格納する変数\n",
    "    for i in range(len(df)):\n",
    "        sorted_row = df.iloc[i].sort_values()   #.ilocでデータフレームの要素を行、列の番号の添字で指定する    #各行の要素を昇順に並び替える\n",
    "        second_smallest_columns = sorted_row.index[1] #各行の2番目に小さい値が格納されているカラム[1]の名前を取得\n",
    "        #second_smallest_label = df.columns.get_loc(second_smallest_index)\n",
    "        index_and_columns_of_second_smallest.append((df.index[i], second_smallest_columns))    #インデックスとカラムのラベル名の組を二次元配列に追加\n",
    "    return index_and_columns_of_second_smallest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#推定精度を算出する関数\n",
    "def calculate_accuracy(index_and_columns_of_second_smallest: list[str, str]) -> tuple[float, list[int]]:\n",
    "    counter = 0\n",
    "    error_index_list = []\n",
    "    for i in range(len(index_and_columns_of_second_smallest)):\n",
    "        #インデックスとカラムのラベル名が同じならばカウンターを1増やす\n",
    "        if index_and_columns_of_second_smallest[i][0] == index_and_columns_of_second_smallest[i][1]:\n",
    "            counter += 1\n",
    "        else:\n",
    "            error_index_list.append(i)\n",
    "            print(f\"間違ってるやつは{i}番目の{index_and_columns_of_second_smallest[i][0]}と{index_and_columns_of_second_smallest[i][1]}です\")\n",
    "\n",
    "    return (counter / len(index_and_columns_of_second_smallest)) * 100, error_index_list  #精度を100分率で返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#入力された加速度の差分のリストからヒストグラムを作る関数（ビンの範囲が全加速度の差分データの最小値〜最大値）\n",
    "def create_histogram(DifferenceAcc_list: list[float]) -> np.histogram:\n",
    "    min_value = min(map(lambda x:max(x), DifferenceAcc_list))   #入力されたリストの中で最も小さい数\n",
    "    max_value = max(map(lambda x:max(x), DifferenceAcc_list))   #入力されたリストの中で最も大きい数\n",
    "\n",
    "    DifferenceAcc_hist = np.zeros((len(DifferenceAcc_list), BINS), dtype=float)\n",
    "\n",
    "    for i in range(len(DifferenceAcc_list)):\n",
    "        DifferenceAcc_hist[i], _ = np.histogram(DifferenceAcc_list[i], bins=BINS, range=(min_value, max_value)) #ヒストグラムを作成し、同じ数のビンで区切る\n",
    "    return DifferenceAcc_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#入力された加速度の差分のリストからヒストグラムを作る関数（ビンの範囲が各加速度の差分データの最小値〜最大値）\n",
    "def create_histogram2(DifferenceAcc_list: list[float]) -> np.histogram:\n",
    "    DifferenceAcc_hist = np.zeros((len(DifferenceAcc_list), BINS), dtype=float)\n",
    "    for i in range(len(DifferenceAcc_list)):\n",
    "        min_value = min(DifferenceAcc_list[i])\n",
    "        max_value = max(DifferenceAcc_list[i])\n",
    "        DifferenceAcc_hist[i], _ = np.histogram(DifferenceAcc_list[i], bins=BINS, range=(min_value, max_value)) #ヒストグラムを作成し、同じ数のビンで区切る\n",
    "    return DifferenceAcc_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KLダイバージェンスとJSダイバージェンス算出の一連の流れを自動化した関数\n",
    "def KL_and_JS(path: str):\n",
    "    Hz_and_filename = get_Hz_and_filename(path)\n",
    "    Hz_and_filename.sort(reverse=True)  #周波数の大きい順にソート\n",
    "    Hz, filename = divide_Hz_and_filename(Hz_and_filename)\n",
    "    Hz = [str(hz) + \"Hz\" for hz in Hz]  #周波数の値+\"Hz\"のリストを作りデータフレームのラベルに用いる\n",
    "\n",
    "    #使う変数を宣言\n",
    "    AccX, AccY, AccZ = [], [], []\n",
    "    ResultantAcc = []\n",
    "    DifferenceAcc_list = []\n",
    "    resultKLD = [[0.0 for j in range(len(filename))] for i in range(len(filename))]  # resultKLDの要素を0.0で初期化\n",
    "    resultJSD = [[0.0 for j in range(len(filename))] for i in range(len(filename))]  # resultKLDの要素を0.0で初期化\n",
    "    error_index_list = []\n",
    "\n",
    "    #各データセットからデータを読み込み静止区間を除去したものを二次元配列に格納\n",
    "    for i in filename:\n",
    "        AccX, AccY, AccZ = get_acceleration(path+i)\n",
    "        ResultantAcc = remove_stationary_intervals(AccX, AccY, AccZ)\n",
    "        DifferenceAcc_list.append(calculate_differences_of_acceleration(ResultantAcc))\n",
    "\n",
    "    #KLダイバージェンスの値を格納\n",
    "    for i in range(len(filename)):\n",
    "        for j in range(len(filename)):\n",
    "            resultKLD[i][j] = KL_divergence(DifferenceAcc_list[i], DifferenceAcc_list[j])\n",
    "\n",
    "    #JSダイバージェンスの値を格納\n",
    "    for i in range(len(filename)):\n",
    "        for j in range(len(filename)):\n",
    "            resultJSD[i][j] = JS_divergence(DifferenceAcc_list[i], DifferenceAcc_list[j])\n",
    "\n",
    "    #結果を出力\n",
    "    df_KLD = pd.DataFrame(resultKLD, index=Hz, columns=Hz)\n",
    "    display(df_KLD)\n",
    "    accuracyKLD, error_index_list = calculate_accuracy(get_index_and_columns_of_second_smallest(df_KLD))\n",
    "    for i in range(len(error_index_list)):\n",
    "        print(filename[error_index_list[i]])\n",
    "    print(f\"KLダイバージェンスによる推定精度は{accuracyKLD}%です\")\n",
    "\n",
    "    df_JSD = pd.DataFrame(resultJSD, index=Hz, columns=Hz)\n",
    "    display(df_JSD)\n",
    "    accuracyJSD, error_index_list = calculate_accuracy(get_index_and_columns_of_second_smallest(df_JSD))\n",
    "    for i in range(len(error_index_list)):\n",
    "        print(filename[error_index_list[i]])\n",
    "    print(f\"JSダイバージェンスによる推定精度は{accuracyJSD}%です\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ランダムフォレストによる機械学習モデル構築と性能評価までを自動化した関数\n",
    "def random_forest(path: str):\n",
    "    Hz_and_filename = get_Hz_and_filename(path)\n",
    "    Hz_and_filename.sort(reverse=True)  #周波数の大きい順にソート\n",
    "    Hz, filename = divide_Hz_and_filename(Hz_and_filename)\n",
    "\n",
    "    #使う変数を宣言\n",
    "    AccX, AccY, AccZ = [], [], []\n",
    "    ResultantAcc = []\n",
    "    DifferenceAcc_list = []\n",
    "\n",
    "    #各データセットからデータを読み込み静止区間を除去したものを二次元配列に格納\n",
    "    for i in filename:\n",
    "        AccX, AccY, AccZ = get_acceleration(path+i)\n",
    "        ResultantAcc = remove_stationary_intervals(AccX, AccY, AccZ)\n",
    "        DifferenceAcc_list.append(calculate_differences_of_acceleration(ResultantAcc))\n",
    "\n",
    "    DifferenceAcc_hist = create_histogram2(DifferenceAcc_list)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(DifferenceAcc_hist, Hz, train_size = TRAIN_SIZE, shuffle = True)\n",
    "\n",
    "    # 学習する\n",
    "    clf = RandomForestClassifier(n_estimators=N_ESTIMATORS, random_state=1234)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(\"正解率 = \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ランダムフォレストによる機械学習モデル構築と性能評価までを自動化した関数\n",
    "def k_neighbors(path: str):\n",
    "    Hz_and_filename = get_Hz_and_filename(path)\n",
    "    Hz_and_filename.sort(reverse=True)  #周波数の大きい順にソート\n",
    "    Hz, filename = divide_Hz_and_filename(Hz_and_filename)\n",
    "\n",
    "    #使う変数を宣言\n",
    "    AccX, AccY, AccZ = [], [], []\n",
    "    ResultantAcc = []\n",
    "    DifferenceAcc_list = []\n",
    "\n",
    "    #各データセットからデータを読み込み静止区間を除去したものを二次元配列に格納\n",
    "    for i in filename:\n",
    "        AccX, AccY, AccZ = get_acceleration(path+i)\n",
    "        ResultantAcc = remove_stationary_intervals(AccX, AccY, AccZ)\n",
    "        DifferenceAcc_list.append(calculate_differences_of_acceleration(ResultantAcc))\n",
    "\n",
    "    DifferenceAcc_hist = create_histogram2(DifferenceAcc_list)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(DifferenceAcc_hist)\n",
    "    newdata = scaler.transform(DifferenceAcc_hist)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(newdata, Hz, train_size = TRAIN_SIZE, shuffle = True)\n",
    "\n",
    "    # 学習する\n",
    "    clf = KNeighborsClassifier()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(\"正解率 = \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"my_walk_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KL_and_JS(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解率 =  0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "k_neighbors(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = \"my_walk_data(only_3classes)/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解率 =  0.47058823529411764\n"
     ]
    }
   ],
   "source": [
    "random_forest(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "#個々実験用\n",
    "Hz_and_filename = get_Hz_and_filename(path)\n",
    "Hz_and_filename.sort(reverse=True)  #周波数の大きい順にソート\n",
    "Hz, filename = divide_Hz_and_filename(Hz_and_filename)\n",
    "\n",
    "#使う変数を宣言\n",
    "AccX, AccY, AccZ = [], [], []\n",
    "ResultantAcc = []\n",
    "DifferenceAcc_list = []\n",
    "\n",
    "    #各データセットからデータを読み込み静止区間を除去したものを二次元配列に格納\n",
    "for i in filename:\n",
    "    AccX, AccY, AccZ = get_acceleration(path+i)\n",
    "    ResultantAcc = remove_stationary_intervals(AccX, AccY, AccZ)\n",
    "    DifferenceAcc_list.append(calculate_differences_of_acceleration(ResultantAcc))\n",
    "\n",
    "DifferenceAcc_hist = create_histogram2(DifferenceAcc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100と111367とwalk100Hz-20230318-200648365.csv\n",
      "\n",
      "100と121304とwalk100Hz-20230315-195146474.csv\n",
      "\n",
      "100と192093とwalk100Hz-20230314-161440229.csv\n",
      "\n",
      "100と94482とwalk100Hz-20230312-164304804.csv\n",
      "\n",
      "100と139361とwalk100Hz-20230312-123621260.csv\n",
      "\n",
      "100と83388とwalk100Hz-20230312-120722989.csv\n",
      "\n",
      "100と153567とwalk100Hz-20230310-173457927.csv\n",
      "\n",
      "100と123136とwalk100Hz-20230309-180537652.csv\n",
      "\n",
      "100と70227とwalk100Hz-20230309-171155001.csv\n",
      "\n",
      "100と78363とwalk100Hz-20230303-111623870.csv\n",
      "\n",
      "100と50417とwalk100Hz-20230302-165446613.csv\n",
      "\n",
      "100と225375とwalk100Hz-20230302-115943109.csv\n",
      "\n",
      "100と74400とwalk100Hz-20230301-203316681.csv\n",
      "\n",
      "100と74082とwalk100Hz-20230228-195310844.csv\n",
      "\n",
      "100と85304とwalk100Hz-20230227-202328538.csv\n",
      "\n",
      "100と177817とwalk100Hz-20230227-194442583.csv\n",
      "\n",
      "90と99138とwalk90Hz-20191004-065122936.csv\n",
      "\n",
      "90と91207とwalk90Hz-20191004-043737805.csv\n",
      "\n",
      "80と92490とwalk80Hz-20191004-065533245.csv\n",
      "\n",
      "80と81597とwalk80Hz-20191004-044153012.csv\n",
      "\n",
      "70と80636とwalk70Hz-20191004-054529826.csv\n",
      "\n",
      "70と70433とwalk70Hz-20191004-033353626.csv\n",
      "\n",
      "60と58271とwalk60Hz-20191004-045347671.csv\n",
      "\n",
      "50と56673とwalk50Hz-20230318-200656663.csv\n",
      "\n",
      "50と60777とwalk50Hz-20230315-195151271.csv\n",
      "\n",
      "50と69252とwalk50Hz-20230314-161434721.csv\n",
      "\n",
      "50と48305とwalk50Hz-20230312-164308701.csv\n",
      "\n",
      "50と69871とwalk50Hz-20230312-123621730.csv\n",
      "\n",
      "50と45130とwalk50Hz-20230312-120723109.csv\n",
      "\n",
      "50と76218とwalk50Hz-20230310-173507115.csv\n",
      "\n",
      "50と63704とwalk50Hz-20230309-180539425.csv\n",
      "\n",
      "50と31651とwalk50Hz-20230309-171159109.csv\n",
      "\n",
      "50と39873とwalk50Hz-20230303-111631944.csv\n",
      "\n",
      "50と26807とwalk50Hz-20230302-165451196.csv\n",
      "\n",
      "50と112809とwalk50Hz-20230302-115947707.csv\n",
      "\n",
      "50と37885とwalk50Hz-20230301-203318690.csv\n",
      "\n",
      "50と36842とwalk50Hz-20230228-195313062.csv\n",
      "\n",
      "50と42225とwalk50Hz-20230227-202335920.csv\n",
      "\n",
      "50と88437とwalk50Hz-20230227-194450631.csv\n",
      "\n",
      "40と46842とwalk40Hz-20191004-071449135.csv\n",
      "\n",
      "40と39857とwalk40Hz-20191004-050047543.csv\n",
      "\n",
      "30と35468とwalk30Hz-20191004-072143788.csv\n",
      "\n",
      "30と29220とwalk30Hz-20191004-050737585.csv\n",
      "\n",
      "20と23447とwalk20Hz-20191004-072740981.csv\n",
      "\n",
      "20と19571とwalk20Hz-20191004-051340670.csv\n",
      "\n",
      "10と11373とwalk10Hz-20230318-200632680.csv\n",
      "\n",
      "10と12155とwalk10Hz-20230315-195135081.csv\n",
      "\n",
      "10と19583とwalk10Hz-20230314-161421803.csv\n",
      "\n",
      "10と10031とwalk10Hz-20230312-164255614.csv\n",
      "\n",
      "10と13978とwalk10Hz-20230312-123610993.csv\n",
      "\n",
      "10と8839とwalk10Hz-20230312-120712467.csv\n",
      "\n",
      "10と15388とwalk10Hz-20230310-173449164.csv\n",
      "\n",
      "10と12682とwalk10Hz-20230309-180534022.csv\n",
      "\n",
      "10と9653とwalk10Hz-20230309-171156758.csv\n",
      "\n",
      "10と8100とwalk10Hz-20230303-111627793.csv\n",
      "\n",
      "10と20832とwalk10Hz-20230302-165445244.csv\n",
      "\n",
      "10と22557とwalk10Hz-20230302-115939846.csv\n",
      "\n",
      "10と7677とwalk10Hz-20230301-203319548.csv\n",
      "\n",
      "10と7511とwalk10Hz-20230228-195310096.csv\n",
      "\n",
      "10と13637とwalk10Hz-20230228-092352670.csv\n",
      "\n",
      "10と6997とwalk10Hz-20230227-213722389.csv\n",
      "\n",
      "10と8543とwalk10Hz-20230227-202332703.csv\n",
      "\n",
      "10と17888とwalk10Hz-20230227-194422371.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(DifferenceAcc_list)):\n",
    "  print(f\"{Hz[i]}と{len(DifferenceAcc_list[i])}と{filename[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinbou = []\n",
    "\n",
    "for i in range(100):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(DifferenceAcc_hist)\n",
    "    newdata = scaler.transform(DifferenceAcc_hist)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(newdata, Hz, train_size = TRAIN_SIZE, shuffle = True)\n",
    "\n",
    "    # 学習する\n",
    "    clf = KNeighborsClassifier()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    kinbou.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33941176470588197\n"
     ]
    }
   ],
   "source": [
    "mink = sum(kinbou) / len(kinbou)\n",
    "print(mink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "#尖度\n",
    "DifferenceAcc_kurtosis = np.zeros(len(DifferenceAcc_list))\n",
    "for i in range(len(DifferenceAcc_hist)):\n",
    "    DifferenceAcc_kurtosis[i] = kurtosis(DifferenceAcc_hist[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "#歪度\n",
    "DifferenceAcc_skewness = np.zeros(len(DifferenceAcc_list))\n",
    "for i in range(len(DifferenceAcc_hist)):\n",
    "    DifferenceAcc_skewness[i] = skew(DifferenceAcc_hist[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分散\n",
    "histogram_var = np.zeros(len(DifferenceAcc_list))\n",
    "for i in range(len(DifferenceAcc_hist)):\n",
    "    histogram_var[i] = np.var(DifferenceAcc_list[i])\n",
    "    #histogram_var[i] = np.var(DifferenceAcc_list[i])/len(DifferenceAcc_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 65.79260793,  64.82257625, 258.78413727,  93.46574104,\n",
       "       154.24801941,  80.93957313, 288.24697085, 377.00916196,\n",
       "        72.59707352,  62.95580836,  81.25694827, 349.01347817,\n",
       "        51.57744453,  64.84587053, 200.34497229, 443.17660575,\n",
       "        87.12374853,  69.43038122, 146.09371484,   7.51203189,\n",
       "       111.43181252, 102.32107071, 119.7497685 , 229.58066698,\n",
       "        10.06647372,  41.26030917, 123.17720033,  94.97312889,\n",
       "       202.28666514,   9.83164446,  19.02180259,  91.13200913,\n",
       "        54.74801277, 148.22079333,  24.98781809,  21.51257551,\n",
       "        50.44863182,  65.38321323,  57.00326428, 174.31118732,\n",
       "        72.18960051, 182.83226125, 302.32873474,  54.76574919,\n",
       "        10.89314727,  74.60272903, 248.75797663,  41.86488221,\n",
       "        41.57931913, 108.15790465, 288.57099289,  32.31143013,\n",
       "        70.65151567,  97.25924627,  26.21060744,  30.09548905,\n",
       "        81.10856659,  24.17250631, 128.7460289 ,  17.35455014,\n",
       "        12.19108975,  51.74359204,  18.79212836, 114.14788211,\n",
       "         3.95203486,   7.42538671,   2.29691884,   9.43663363,\n",
       "        87.07351798,  17.77731136,  63.6113961 ,  20.36728867,\n",
       "        67.96322276,  45.18897011,  11.19000212,   3.32901059,\n",
       "       268.28606834, 109.65425426,   1.13992179,   3.8846674 ,\n",
       "        59.2216591 ,   4.4102838 ,  98.67912072, 367.89583409])"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DifferenceAcc_kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.87615704,  7.52723461, 14.95354541,  9.26587951, 11.64261595,\n",
       "        8.62596173, 15.89487234, 18.45369053,  8.17061332,  7.72880134,\n",
       "        8.59598098, 17.71225195,  7.08869387,  7.64948758, 13.03714102,\n",
       "       19.7380418 ,  8.64306515,  7.93061426, 11.26660011,  2.93191233,\n",
       "        9.99544253,  9.17405582, 10.08316242, 14.15095597,  3.29574055,\n",
       "        6.17388856, 10.09656553,  8.92879779, 13.25407645,  3.25026161,\n",
       "        4.23764072,  8.68937049,  7.10496697, 11.27282309,  4.77748362,\n",
       "        4.60263347,  6.63493834,  7.75831598,  7.28745365, 12.27418839,\n",
       "        8.05399356, 12.53584859, 16.39078498,  7.16745364,  3.37080515,\n",
       "        8.29696719, 14.81380602,  6.41906919,  6.23256143,  9.44014958,\n",
       "       15.61564787,  5.42920026,  7.65778095,  9.14357827,  4.97723171,\n",
       "        5.11854252,  7.95711152,  4.80441082, 10.49666726,  4.09466108,\n",
       "        3.52536242,  6.38576261,  4.27335137,  9.7846631 ,  2.0979605 ,\n",
       "        2.74510072,  1.74037599,  2.99015031,  8.34864977,  4.13581041,\n",
       "        7.26414414,  4.41250218,  7.40999734,  6.17013984,  3.34276255,\n",
       "        1.85341233, 15.07529915,  9.63968943,  1.33041658,  2.04268115,\n",
       "        5.57474239,  2.20374204,  8.48096561, 17.24915503])"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DifferenceAcc_skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.93053204e+15, 4.84575364e+16, 9.45944237e+16, 2.89494524e+17,\n",
       "       7.46482330e+16, 4.33553387e+17, 1.79046686e+16, 5.59904623e+15,\n",
       "       7.29483273e+15, 9.30644499e+15, 1.25765653e+16, 9.00768677e+15,\n",
       "       3.94728075e+15, 2.67822934e+16, 2.23368926e+16, 9.51268817e+15,\n",
       "       3.81116630e+16, 2.90924690e+16, 1.39545526e+16, 3.48645305e+15,\n",
       "       2.92023766e+16, 3.67312680e+16, 3.05854059e+16, 1.53699257e+16,\n",
       "       4.32206679e+15, 1.65423860e+16, 5.01081293e+16, 4.75307546e+16,\n",
       "       1.73272513e+16, 6.40573222e+15, 1.55688716e+16, 9.16315759e+16,\n",
       "       7.77139200e+16, 2.27248842e+16, 2.06558073e+16, 1.97647454e+16,\n",
       "       9.84446521e+16, 2.66817174e+17, 6.06003748e+17, 3.04520075e+17,\n",
       "       6.46097431e+17, 3.45415214e+16, 1.27885002e+16, 2.03523389e+16,\n",
       "       3.17393256e+16, 3.21383434e+16, 1.50658412e+16, 9.73358158e+15,\n",
       "       2.64536153e+16, 3.23730918e+16, 1.42029591e+16, 1.42681531e+17,\n",
       "       9.29818881e+16, 3.41177076e+16, 1.75087046e+16, 4.18296865e+16,\n",
       "       1.14720146e+17, 1.00961954e+17, 4.87689677e+16, 2.64116746e+16,\n",
       "       4.55709227e+16, 1.97407973e+17, 1.90686733e+17, 7.32670198e+16,\n",
       "       3.76206569e+16, 7.88359252e+16, 8.21284640e+16, 1.96358066e+17,\n",
       "       2.72466085e+17, 9.02500123e+17, 2.59105916e+17, 1.18978599e+18,\n",
       "       6.66762849e+16, 2.36581676e+16, 3.43069696e+16, 1.32035530e+17,\n",
       "       1.99534829e+16, 3.55458616e+16, 7.42498942e+16, 1.50509813e+17,\n",
       "       1.19068421e+17, 1.97290104e+17, 9.12780895e+16, 4.71999210e+16])"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histogram_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.concatenate((DifferenceAcc_kurtosis.reshape(-1, 1), DifferenceAcc_skewness.reshape(-1, 1), histogram_var.reshape(-1, 1)), axis=1)\n",
    "X = np.concatenate((DifferenceAcc_hist, X_new), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.57926079e+01, 7.87615704e+00, 7.93053204e+15])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解率 =  0.47058823529411764\n"
     ]
    }
   ],
   "source": [
    "#ヒストグラム+尖度+歪度+分散\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Hz, train_size = TRAIN_SIZE, shuffle = True)\n",
    "clf = RandomForestClassifier(random_state=1234)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(\"正解率 = \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解率 =  0.47058823529411764\n"
     ]
    }
   ],
   "source": [
    "#ヒストグラム\n",
    "x_train, x_test, y_train, y_test = train_test_split(DifferenceAcc_hist, Hz, train_size = TRAIN_SIZE, shuffle = True)\n",
    "clf = RandomForestClassifier(random_state=1234)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(\"正解率 = \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解率 =  0.29411764705882354\n"
     ]
    }
   ],
   "source": [
    "#尖度+歪度+分散\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_new, Hz, train_size = TRAIN_SIZE, shuffle = True)\n",
    "clf = RandomForestClassifier(random_state=1234)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(\"正解率 = \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_kurts = []\n",
    "only_hist = []\n",
    "kurtskewvar = []\n",
    "\n",
    "for i in range(100):\n",
    "    #ヒストグラム+尖度+歪度+分散\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Hz, train_size = TRAIN_SIZE, shuffle = True)\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    hist_kurts.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    #ヒストグラム\n",
    "    x_train, x_test, y_train, y_test = train_test_split(DifferenceAcc_hist, Hz, train_size = TRAIN_SIZE, shuffle = True)\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    only_hist.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    #尖度+歪度+分散\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_new, Hz, train_size = TRAIN_SIZE, shuffle = True)\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    kurtskewvar.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ヒスト+尖度+歪度+分散の精度：0.4870588235294116\n",
      "ヒストグラムのみの精度:0.49\n",
      "尖度+歪度+分散だけの精度:0.21882352941176442\n"
     ]
    }
   ],
   "source": [
    "min_hist_kurts = sum(hist_kurts) / len(hist_kurts)\n",
    "min_only_hist = sum(only_hist) / len(only_hist)\n",
    "min_kurtskewvar = sum(kurtskewvar) / len(kurtskewvar)\n",
    "print(f\"ヒスト+尖度+歪度+分散の精度：{min_hist_kurts}\\nヒストグラムのみの精度:{min_only_hist}\\n尖度+歪度+分散だけの精度:{min_kurtskewvar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "919e6181955fbc636a96e4fdb04fb1b969c9681582829f05a2534c8d07862e2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
